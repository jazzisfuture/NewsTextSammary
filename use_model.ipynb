{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd05509c4c259a5a49102f826d234aea18f0c83b903638cb80c1a627f502e3896ba",
   "display_name": "Python 3.7.7 64-bit ('pytorch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys,os\n",
    "sys.path.append(os.pardir)\n",
    "from bert_seq2seq.tokenizer import Tokenizer, load_chinese_base_vocab\n",
    "import json\n",
    "import time\n",
    "import bert_seq2seq\n",
    "from bert_seq2seq.utils import load_bert\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"./model_file/trained_model/summary_roberta_wwm.bin\"\n",
    "model2 = \"./model_file/trained_model/summary_roberta_wwm_256.bin\"\n",
    "model_int8=\"./model_file/trained_model/int8_roberta.pth\"\n",
    "# pretrian = \"./model_file/roberta_wwm.bin\"\n",
    "vocab_text = \"./vocab/vocab.txt\"\n",
    "model_name = \"roberta\"\n",
    "# writer = SummaryWriter(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_int8 = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "精简后的词表大小为：13584\n",
      "./model_file/trained_model/summary_roberta_wwm.bin loaded!\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Seq2SeqModel:\n\tMissing key(s) in state_dict: \"bert.encoder.layer.0.attention.self.query.weight\", \"bert.encoder.layer.0.attention.self.query.bias\", \"bert.encoder.layer.0.attention.self.key.weight\", \"bert.encoder.layer.0.attention.self.key.bias\", \"bert.encoder.layer.0.attention.self.value.weight\", \"bert.encoder.layer.0.attention.self.value.bias\", \"bert.encoder.layer.0.attention.output.dense.weight\", \"bert.encoder.layer.0.attention.output.dense.bias\", \"bert.encoder.layer.0.intermediate.dense.weight\", \"bert.encoder.layer.0.intermediate.dense.bias\", \"bert.encoder.layer.0.output.dense.weight\", \"bert.encoder.layer.0.output.dense.bias\", \"bert.encoder.layer.1.attention.self.query.weight\", \"bert.encoder.layer.1.attention.self.query.bias\", \"bert.encoder.layer.1.attention.self.key.weight\", \"bert.encoder.layer.1.attention.self.key.bias\", \"bert.encoder.layer.1.attention.self.value.weight\", \"bert.encoder.layer.1.attention.self.value.bias\", \"bert.encoder.layer.1.attention.output.dense.weight\", \"bert.encoder.layer.1.attention.output.dense.bias\", \"bert.encoder.layer.1.intermediate.dense.weight\", \"bert.encoder.layer.1.intermediate.dense.bias\", \"bert.encoder.layer.1.output.dense.weight\", \"bert.encoder.layer.1.output.dense.bias\", \"bert.encoder.layer.2.attention.self.query.weight\", \"bert.encoder.layer.2.attention.self.query.bias\", \"bert.encoder.layer.2.attention.self.key.weight\", \"bert.encoder.layer.2.attention.self.key.bias\", \"bert.encoder.layer.2.attention.self.value.weight\", \"bert.encoder.layer.2.attention.self.value.bias\", \"bert.encoder.layer.2.attention.output.dense.weight\", \"bert.encoder.layer.2.attention.output.dense.bias\", \"bert.encoder.layer.2.intermediate.dense.weight\", \"bert.encoder.layer.2.intermediate.dense.bias\", \"bert.encoder.layer.2.output.dense.weight\", \"bert.encoder.layer.2.output.dense.bias\", \"bert.encoder.layer.3.attention.self.query.weight\", \"bert.encoder.layer.3.attention.self.query.bias\", \"bert.encoder.layer.3.attention.self.key.weight\", \"bert.encoder.layer.3.attention.self.key.bias\", \"bert.encoder.layer.3.attention.self.value.weight\", \"bert.encoder.layer.3.attention.self.value.bias\", \"bert.encoder.layer.3.attention.output.dense.weight\", \"bert.encoder.layer.3.attention.output.dense.bias\", \"bert.encoder.layer.3.intermediate.dense.weight\", \"bert.encoder.layer.3.intermediate.dense.bias\", \"bert.encoder.layer.3.output.dense.weight\", \"bert.encoder.layer.3.output.dense.bias\", \"bert.encoder.layer.4.attention.self.query.weight\", \"bert.encoder.layer.4.attention.self.query.bias\", \"bert.encoder.layer.4.attention.self.key.weight\", \"bert.encoder.layer.4.attention.self.key.bias\", \"bert.encoder.layer.4.attention.self.value.weight\", \"bert.encoder.layer.4.attention.self.value.bias\", \"bert.encoder.layer.4.attention.output.dense.weight\", \"bert.encoder.layer.4.attention.output.dense.bias\", \"bert.encoder.layer.4.intermediate.dense.weight\", \"bert.encoder.layer.4.intermediate.dense.bias\", \"bert.encoder.layer.4.output.dense.weight\", \"bert.encoder.layer.4.output.dense.bias\", \"bert.encoder.layer.5.attention.self.query.weight\", \"bert.encoder.layer.5.attention.self.query.bias\", \"bert.encoder.layer.5.attention.self.key.weight\", \"bert.encoder.layer.5.attention.self.key.bias\", \"bert.encoder.layer.5.attention.self.value.weight\", \"bert.encoder.layer.5.attention.self.value.bias\", \"bert.encoder.layer.5.attention.output.dense.weight\", \"bert.encoder.layer.5.attention.output.dense.bias\", \"bert.encoder.layer.5.intermediate.dense.weight\", \"bert.encoder.layer.5.intermediate.dense.bias\", \"bert.encoder.layer.5.output.dense.weight\", \"bert.encoder.layer.5.output.dense.bias\", \"bert.encoder.layer.6.attention.self.query.weight\", \"bert.encoder.layer.6.attention.self.query.bias\", \"bert.encoder.layer.6.attention.self.key.weight\", \"bert.encoder.layer.6.attention.self.key.bias\", \"bert.encoder.layer.6.attention.self.value.weight\", \"bert.encoder.layer.6.attention.self.value.bias\", \"bert.encoder.layer.6.attention.output.dense.weight\", \"bert.encoder.layer.6.attention.output.dense.bias\", \"bert.encoder.layer.6.intermediate.dense.weight\", \"bert.encoder.layer.6.intermediate.dense.bias\", \"bert.encoder.layer.6.output.dense.weight\", \"bert.encoder.layer.6.output.dense.bias\", \"bert.encoder.layer.7.attention.self.query.weight\", \"bert.encoder.layer.7.attention.self.query.bias\", \"bert.encoder.layer.7.attention.self.key.weight\", \"bert.encoder.layer.7.attention.self.key.bias\", \"bert.encoder.layer.7.attention.self.value.weight\", \"bert.encoder.layer.7.attention.self.value.bias\", \"bert.encoder.layer.7.attention.output.dense.weight\", \"bert.encoder.layer.7.attention.output.dense.bias\", \"bert.encoder.layer.7.intermediate.dense.weight\", \"bert.encoder.layer.7.intermediate.dense.bias\", \"bert.encoder.layer.7.output.dense.weight\", \"bert.encoder.layer.7.output.dense.bias\", \"bert.encoder.layer.8.attention.self.query.weight\", \"bert.encoder.layer.8.attention.self.query.bias\", \"bert.encoder.layer.8.attention.self.key.weight\", \"bert.encoder.layer.8.attention.self.key.bias\", \"bert.encoder.layer.8.attention.self.value.weight\", \"bert.encoder.layer.8.attention.self.value.bias\", \"bert.encoder.layer.8.attention.output.dense.weight\", \"bert.encoder.layer.8.attention.output.dense.bias\", \"bert.encoder.layer.8.intermediate.dense.weight\", \"bert.encoder.layer.8.intermediate.dense.bias\", \"bert.encoder.layer.8.output.dense.weight\", \"bert.encoder.layer.8.output.dense.bias\", \"bert.encoder.layer.9.attention.self.query.weight\", \"bert.encoder.layer.9.attention.self.query.bias\", \"bert.encoder.layer.9.attention.self.key.weight\", \"bert.encoder.layer.9.attention.self.key.bias\", \"bert.encoder.layer.9.attention.self.value.weight\", \"bert.encoder.layer.9.attention.self.value.bias\", \"bert.encoder.layer.9.attention.output.dense.weight\", \"bert.encoder.layer.9.attention.output.dense.bias\", \"bert.encoder.layer.9.intermediate.dense.weight\", \"bert.encoder.layer.9.intermediate.dense.bias\", \"bert.encoder.layer.9.output.dense.weight\", \"bert.encoder.layer.9.output.dense.bias\", \"bert.encoder.layer.10.attention.self.query.weight\", \"bert.encoder.layer.10.attention.self.query.bias\", \"bert.encoder.layer.10.attention.self.key.weight\", \"bert.encoder.layer.10.attention.self.key.bias\", \"bert.encoder.layer.10.attention.self.value.weight\", \"bert.encoder.layer.10.attention.self.value.bias\", \"bert.encoder.layer.10.attention.output.dense.weight\", \"bert.encoder.layer.10.attention.output.dense.bias\", \"bert.encoder.layer.10.intermediate.dense.weight\", \"bert.encoder.layer.10.intermediate.dense.bias\", \"bert.encoder.layer.10.output.dense.weight\", \"bert.encoder.layer.10.output.dense.bias\", \"bert.encoder.layer.11.attention.self.query.weight\", \"bert.encoder.layer.11.attention.self.query.bias\", \"bert.encoder.layer.11.attention.self.key.weight\", \"bert.encoder.layer.11.attention.self.key.bias\", \"bert.encoder.layer.11.attention.self.value.weight\", \"bert.encoder.layer.11.attention.self.value.bias\", \"bert.encoder.layer.11.attention.output.dense.weight\", \"bert.encoder.layer.11.attention.output.dense.bias\", \"bert.encoder.layer.11.intermediate.dense.weight\", \"bert.encoder.layer.11.intermediate.dense.bias\", \"bert.encoder.layer.11.output.dense.weight\", \"bert.encoder.layer.11.output.dense.bias\", \"bert.pooler.dense.weight\", \"bert.pooler.dense.bias\", \"decoder.transform.dense.weight\", \"decoder.transform.dense.bias\", \"decoder.decoder.weight\", \"decoder.decoder.bias\". \n\tUnexpected key(s) in state_dict: \"bert.encoder.layer.0.attention.self.query.scale\", \"bert.encoder.layer.0.attention.self.query.zero_point\", \"bert.encoder.layer.0.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.0.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.0.attention.self.key.scale\", \"bert.encoder.layer.0.attention.self.key.zero_point\", \"bert.encoder.layer.0.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.0.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.0.attention.self.value.scale\", \"bert.encoder.layer.0.attention.self.value.zero_point\", \"bert.encoder.layer.0.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.0.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.0.attention.output.dense.scale\", \"bert.encoder.layer.0.attention.output.dense.zero_point\", \"bert.encoder.layer.0.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.0.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.0.intermediate.dense.scale\", \"bert.encoder.layer.0.intermediate.dense.zero_point\", \"bert.encoder.layer.0.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.0.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.0.output.dense.scale\", \"bert.encoder.layer.0.output.dense.zero_point\", \"bert.encoder.layer.0.output.dense._packed_params.dtype\", \"bert.encoder.layer.0.output.dense._packed_params._packed_params\", \"bert.encoder.layer.1.attention.self.query.scale\", \"bert.encoder.layer.1.attention.self.query.zero_point\", \"bert.encoder.layer.1.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.1.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.1.attention.self.key.scale\", \"bert.encoder.layer.1.attention.self.key.zero_point\", \"bert.encoder.layer.1.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.1.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.1.attention.self.value.scale\", \"bert.encoder.layer.1.attention.self.value.zero_point\", \"bert.encoder.layer.1.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.1.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.1.attention.output.dense.scale\", \"bert.encoder.layer.1.attention.output.dense.zero_point\", \"bert.encoder.layer.1.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.1.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.1.intermediate.dense.scale\", \"bert.encoder.layer.1.intermediate.dense.zero_point\", \"bert.encoder.layer.1.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.1.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.1.output.dense.scale\", \"bert.encoder.layer.1.output.dense.zero_point\", \"bert.encoder.layer.1.output.dense._packed_params.dtype\", \"bert.encoder.layer.1.output.dense._packed_params._packed_params\", \"bert.encoder.layer.2.attention.self.query.scale\", \"bert.encoder.layer.2.attention.self.query.zero_point\", \"bert.encoder.layer.2.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.2.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.2.attention.self.key.scale\", \"bert.encoder.layer.2.attention.self.key.zero_point\", \"bert.encoder.layer.2.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.2.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.2.attention.self.value.scale\", \"bert.encoder.layer.2.attention.self.value.zero_point\", \"bert.encoder.layer.2.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.2.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.2.attention.output.dense.scale\", \"bert.encoder.layer.2.attention.output.dense.zero_point\", \"bert.encoder.layer.2.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.2.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.2.intermediate.dense.scale\", \"bert.encoder.layer.2.intermediate.dense.zero_point\", \"bert.encoder.layer.2.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.2.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.2.output.dense.scale\", \"bert.encoder.layer.2.output.dense.zero_point\", \"bert.encoder.layer.2.output.dense._packed_params.dtype\", \"bert.encoder.layer.2.output.dense._packed_params._packed_params\", \"bert.encoder.layer.3.attention.self.query.scale\", \"bert.encoder.layer.3.attention.self.query.zero_point\", \"bert.encoder.layer.3.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.3.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.3.attention.self.key.scale\", \"bert.encoder.layer.3.attention.self.key.zero_point\", \"bert.encoder.layer.3.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.3.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.3.attention.self.value.scale\", \"bert.encoder.layer.3.attention.self.value.zero_point\", \"bert.encoder.layer.3.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.3.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.3.attention.output.dense.scale\", \"bert.encoder.layer.3.attention.output.dense.zero_point\", \"bert.encoder.layer.3.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.3.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.3.intermediate.dense.scale\", \"bert.encoder.layer.3.intermediate.dense.zero_point\", \"bert.encoder.layer.3.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.3.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.3.output.dense.scale\", \"bert.encoder.layer.3.output.dense.zero_point\", \"bert.encoder.layer.3.output.dense._packed_params.dtype\", \"bert.encoder.layer.3.output.dense._packed_params._packed_params\", \"bert.encoder.layer.4.attention.self.query.scale\", \"bert.encoder.layer.4.attention.self.query.zero_point\", \"bert.encoder.layer.4.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.4.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.4.attention.self.key.scale\", \"bert.encoder.layer.4.attention.self.key.zero_point\", \"bert.encoder.layer.4.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.4.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.4.attention.self.value.scale\", \"bert.encoder.layer.4.attention.self.value.zero_point\", \"bert.encoder.layer.4.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.4.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.4.attention.output.dense.scale\", \"bert.encoder.layer.4.attention.output.dense.zero_point\", \"bert.encoder.layer.4.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.4.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.4.intermediate.dense.scale\", \"bert.encoder.layer.4.intermediate.dense.zero_point\", \"bert.encoder.layer.4.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.4.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.4.output.dense.scale\", \"bert.encoder.layer.4.output.dense.zero_point\", \"bert.encoder.layer.4.output.dense._packed_params.dtype\", \"bert.encoder.layer.4.output.dense._packed_params._packed_params\", \"bert.encoder.layer.5.attention.self.query.scale\", \"bert.encoder.layer.5.attention.self.query.zero_point\", \"bert.encoder.layer.5.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.5.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.5.attention.self.key.scale\", \"bert.encoder.layer.5.attention.self.key.zero_point\", \"bert.encoder.layer.5.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.5.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.5.attention.self.value.scale\", \"bert.encoder.layer.5.attention.self.value.zero_point\", \"bert.encoder.layer.5.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.5.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.5.attention.output.dense.scale\", \"bert.encoder.layer.5.attention.output.dense.zero_point\", \"bert.encoder.layer.5.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.5.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.5.intermediate.dense.scale\", \"bert.encoder.layer.5.intermediate.dense.zero_point\", \"bert.encoder.layer.5.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.5.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.5.output.dense.scale\", \"bert.encoder.layer.5.output.dense.zero_point\", \"bert.encoder.layer.5.output.dense._packed_params.dtype\", \"bert.encoder.layer.5.output.dense._packed_params._packed_params\", \"bert.encoder.layer.6.attention.self.query.scale\", \"bert.encoder.layer.6.attention.self.query.zero_point\", \"bert.encoder.layer.6.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.6.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.6.attention.self.key.scale\", \"bert.encoder.layer.6.attention.self.key.zero_point\", \"bert.encoder.layer.6.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.6.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.6.attention.self.value.scale\", \"bert.encoder.layer.6.attention.self.value.zero_point\", \"bert.encoder.layer.6.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.6.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.6.attention.output.dense.scale\", \"bert.encoder.layer.6.attention.output.dense.zero_point\", \"bert.encoder.layer.6.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.6.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.6.intermediate.dense.scale\", \"bert.encoder.layer.6.intermediate.dense.zero_point\", \"bert.encoder.layer.6.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.6.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.6.output.dense.scale\", \"bert.encoder.layer.6.output.dense.zero_point\", \"bert.encoder.layer.6.output.dense._packed_params.dtype\", \"bert.encoder.layer.6.output.dense._packed_params._packed_params\", \"bert.encoder.layer.7.attention.self.query.scale\", \"bert.encoder.layer.7.attention.self.query.zero_point\", \"bert.encoder.layer.7.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.7.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.7.attention.self.key.scale\", \"bert.encoder.layer.7.attention.self.key.zero_point\", \"bert.encoder.layer.7.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.7.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.7.attention.self.value.scale\", \"bert.encoder.layer.7.attention.self.value.zero_point\", \"bert.encoder.layer.7.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.7.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.7.attention.output.dense.scale\", \"bert.encoder.layer.7.attention.output.dense.zero_point\", \"bert.encoder.layer.7.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.7.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.7.intermediate.dense.scale\", \"bert.encoder.layer.7.intermediate.dense.zero_point\", \"bert.encoder.layer.7.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.7.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.7.output.dense.scale\", \"bert.encoder.layer.7.output.dense.zero_point\", \"bert.encoder.layer.7.output.dense._packed_params.dtype\", \"bert.encoder.layer.7.output.dense._packed_params._packed_params\", \"bert.encoder.layer.8.attention.self.query.scale\", \"bert.encoder.layer.8.attention.self.query.zero_point\", \"bert.encoder.layer.8.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.8.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.8.attention.self.key.scale\", \"bert.encoder.layer.8.attention.self.key.zero_point\", \"bert.encoder.layer.8.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.8.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.8.attention.self.value.scale\", \"bert.encoder.layer.8.attention.self.value.zero_point\", \"bert.encoder.layer.8.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.8.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.8.attention.output.dense.scale\", \"bert.encoder.layer.8.attention.output.dense.zero_point\", \"bert.encoder.layer.8.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.8.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.8.intermediate.dense.scale\", \"bert.encoder.layer.8.intermediate.dense.zero_point\", \"bert.encoder.layer.8.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.8.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.8.output.dense.scale\", \"bert.encoder.layer.8.output.dense.zero_point\", \"bert.encoder.layer.8.output.dense._packed_params.dtype\", \"bert.encoder.layer.8.output.dense._packed_params._packed_params\", \"bert.encoder.layer.9.attention.self.query.scale\", \"bert.encoder.layer.9.attention.self.query.zero_point\", \"bert.encoder.layer.9.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.9.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.9.attention.self.key.scale\", \"bert.encoder.layer.9.attention.self.key.zero_point\", \"bert.encoder.layer.9.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.9.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.9.attention.self.value.scale\", \"bert.encoder.layer.9.attention.self.value.zero_point\", \"bert.encoder.layer.9.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.9.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.9.attention.output.dense.scale\", \"bert.encoder.layer.9.attention.output.dense.zero_point\", \"bert.encoder.layer.9.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.9.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.9.intermediate.dense.scale\", \"bert.encoder.layer.9.intermediate.dense.zero_point\", \"bert.encoder.layer.9.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.9.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.9.output.dense.scale\", \"bert.encoder.layer.9.output.dense.zero_point\", \"bert.encoder.layer.9.output.dense._packed_params.dtype\", \"bert.encoder.layer.9.output.dense._packed_params._packed_params\", \"bert.encoder.layer.10.attention.self.query.scale\", \"bert.encoder.layer.10.attention.self.query.zero_point\", \"bert.encoder.layer.10.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.10.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.10.attention.self.key.scale\", \"bert.encoder.layer.10.attention.self.key.zero_point\", \"bert.encoder.layer.10.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.10.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.10.attention.self.value.scale\", \"bert.encoder.layer.10.attention.self.value.zero_point\", \"bert.encoder.layer.10.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.10.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.10.attention.output.dense.scale\", \"bert.encoder.layer.10.attention.output.dense.zero_point\", \"bert.encoder.layer.10.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.10.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.10.intermediate.dense.scale\", \"bert.encoder.layer.10.intermediate.dense.zero_point\", \"bert.encoder.layer.10.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.10.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.10.output.dense.scale\", \"bert.encoder.layer.10.output.dense.zero_point\", \"bert.encoder.layer.10.output.dense._packed_params.dtype\", \"bert.encoder.layer.10.output.dense._packed_params._packed_params\", \"bert.encoder.layer.11.attention.self.query.scale\", \"bert.encoder.layer.11.attention.self.query.zero_point\", \"bert.encoder.layer.11.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.11.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.11.attention.self.key.scale\", \"bert.encoder.layer.11.attention.self.key.zero_point\", \"bert.encoder.layer.11.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.11.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.11.attention.self.value.scale\", \"bert.encoder.layer.11.attention.self.value.zero_point\", \"bert.encoder.layer.11.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.11.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.11.attention.output.dense.scale\", \"bert.encoder.layer.11.attention.output.dense.zero_point\", \"bert.encoder.layer.11.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.11.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.11.intermediate.dense.scale\", \"bert.encoder.layer.11.intermediate.dense.zero_point\", \"bert.encoder.layer.11.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.11.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.11.output.dense.scale\", \"bert.encoder.layer.11.output.dense.zero_point\", \"bert.encoder.layer.11.output.dense._packed_params.dtype\", \"bert.encoder.layer.11.output.dense._packed_params._packed_params\", \"bert.pooler.dense.scale\", \"bert.pooler.dense.zero_point\", \"bert.pooler.dense._packed_params.dtype\", \"bert.pooler.dense._packed_params._packed_params\", \"decoder.transform.dense.scale\", \"decoder.transform.dense.zero_point\", \"decoder.transform.dense._packed_params.dtype\", \"decoder.transform.dense._packed_params._packed_params\", \"decoder.decoder.scale\", \"decoder.decoder.zero_point\", \"decoder.decoder._packed_params.dtype\", \"decoder.decoder._packed_params._packed_params\". ",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e304327da92d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mbert_model2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice_int8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mbert_model2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mbert_model2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_all_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_int8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice_int8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mf:\\我的坚果云\\毕业论文\\code\\bert_seq2seq-master\\bert_seq2seq-master\\bert_seq2seq\\basic_bert.py\u001b[0m in \u001b[0;36mload_all_params\u001b[1;34m(self, model_path, device)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload_all_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"cuda\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" loaded!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m-> 1052\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m   1053\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Seq2SeqModel:\n\tMissing key(s) in state_dict: \"bert.encoder.layer.0.attention.self.query.weight\", \"bert.encoder.layer.0.attention.self.query.bias\", \"bert.encoder.layer.0.attention.self.key.weight\", \"bert.encoder.layer.0.attention.self.key.bias\", \"bert.encoder.layer.0.attention.self.value.weight\", \"bert.encoder.layer.0.attention.self.value.bias\", \"bert.encoder.layer.0.attention.output.dense.weight\", \"bert.encoder.layer.0.attention.output.dense.bias\", \"bert.encoder.layer.0.intermediate.dense.weight\", \"bert.encoder.layer.0.intermediate.dense.bias\", \"bert.encoder.layer.0.output.dense.weight\", \"bert.encoder.layer.0.output.dense.bias\", \"bert.encoder.layer.1.attention.self.query.weight\", \"bert.encoder.layer.1.attention.self.query.bias\", \"bert.encoder.layer.1.attention.self.key.weight\", \"bert.encoder.layer.1.attention.self.key.bias\", \"bert.encoder.layer.1.attention.self.value.weight\", \"bert.encoder.layer.1.attention.self.value.bias\", \"bert.encoder.layer.1.attention.output.dense.weight\", \"bert.encoder.layer.1.attention.output.dense.bias\", \"bert.encoder.layer.1.intermediate.dense.weight\", \"bert.encoder.layer.1.intermediate.dense.bias\", \"bert.encoder.layer.1.output.dense.weight\", \"bert.encoder.layer.1.output.dense.bias\", \"bert.encoder.layer.2.attention.self.query.weight\", \"bert.encoder.layer.2.attention.self.query.bias\", \"bert.encoder.layer.2.attention.self.key.weight\", \"bert.encoder.layer.2.attention.self.key.bias\", \"bert.encoder.layer.2.attention.self.value.weight\", \"bert.encoder.layer.2.attention.self.value.bias\", \"bert.encoder.layer.2.attention.output.dense.weight\", \"bert.encoder.layer.2.attention.output.dense.bias\", \"bert.encoder.layer.2.intermediate.dense.weight\", \"bert.encoder.layer.2.intermediate.dense.bias\", \"bert.encoder.layer.2.output.dense.weight\", \"bert.encoder.layer.2.output.dense.bias\", \"bert.encoder.layer.3.attention.self.query.weight\", \"bert.encoder.layer.3.attention.self.query.bias\", \"bert.encoder.layer.3.attention.self.key.weight\", \"bert.encoder.layer.3.attention.self.key.bias\", \"bert.encoder.layer.3.attention.self.value.weight\", \"bert.encoder.layer.3.attention.self.value.bias\", \"bert.encoder.layer.3.attention.output.dense.weight\", \"bert.encoder.layer.3.attention.output.dense.bias\", \"bert.encoder.layer.3.intermediate.dense.weight\", \"bert.encoder.layer.3.intermediate.dense.bias\", \"bert.encoder.layer.3.output.dense.weight\", \"bert.encoder.layer.3.output.dense.bias\", \"bert.encoder.layer.4.attention.self.query.weight\", \"bert.encoder.layer.4.attention.self.query.bias\", \"bert.encoder.layer.4.attention.self.key.weight\", \"bert.encoder.layer.4.attention.self.key.bias\", \"bert.encoder.layer.4.attention.self.value.weight\", \"bert.encoder.layer.4.attention.self.value.bias\", \"bert.encoder.layer.4.attention.output.dense.weight\", \"bert.encoder.layer.4.attention.output.dense.bias\", \"bert.encoder.layer.4.intermediate.dense.weight\", \"bert.encoder.layer.4.intermediate.dense.bias\", \"bert.encoder.layer.4.output.dense.weight\", \"bert.encoder.layer.4.output.dense.bias\", \"bert.encoder.layer.5.attention.self.query.weight\", \"bert.encoder.layer.5.attention.self.query.bias\", \"bert.encoder.layer.5.attention.self.key.weight\", \"bert.encoder.layer.5.attention.self.key.bias\", \"bert.encoder.layer.5.attention.self.value.weight\", \"bert.encoder.layer.5.attention.self.value.bias\", \"bert.encoder.layer.5.attention.output.dense.weight\", \"bert.encoder.layer.5.attention.output.dense.bias\", \"bert.encoder.layer.5.intermediate.dense.weight\", \"bert.encoder.layer.5.intermediate.dense.bias\", \"bert.encoder.layer.5.output.dense.weight\", \"bert.encoder.layer.5.output.dense.bias\", \"bert.encoder.layer.6.attention.self.query.weight\", \"bert.encoder.layer.6.attention.self.query.bias\", \"bert.encoder.layer.6.attention.self.key.weight\", \"bert.encoder.layer.6.attention.self.key.bias\", \"bert.encoder.layer.6.attention.self.value.weight\", \"bert.encoder.layer.6.attention.self.value.bias\", \"bert.encoder.layer.6.attention.output.dense.weight\", \"bert.encoder.layer.6.attention.output.dense.bias\", \"bert.encoder.layer.6.intermediate.dense.weight\", \"bert.encoder.layer.6.intermediate.dense.bias\", \"bert.encoder.layer.6.output.dense.weight\", \"bert.encoder.layer.6.output.dense.bias\", \"bert.encoder.layer.7.attention.self.query.weight\", \"bert.encoder.layer.7.attention.self.query.bias\", \"bert.encoder.layer.7.attention.self.key.weight\", \"bert.encoder.layer.7.attention.self.key.bias\", \"bert.encoder.layer.7.attention.self.value.weight\", \"bert.encoder.layer.7.attention.self.value.bias\", \"bert.encoder.layer.7.attention.output.dense.weight\", \"bert.encoder.layer.7.attention.output.dense.bias\", \"bert.encoder.layer.7.intermediate.dense.weight\", \"bert.encoder.layer.7.intermediate.dense.bias\", \"bert.encoder.layer.7.output.dense.weight\", \"bert.encoder.layer.7.output.dense.bias\", \"bert.encoder.layer.8.attention.self.query.weight\", \"bert.encoder.layer.8.attention.self.query.bias\", \"bert.encoder.layer.8.attention.self.key.weight\", \"bert.encoder.layer.8.attention.self.key.bias\", \"bert.encoder.layer.8.attention.self.value.weight\", \"bert.encoder.layer.8.attention.self.value.bias\", \"bert.encoder.layer.8.attention.output.dense.weight\", \"bert.encoder.layer.8.attention.output.dense.bias\", \"bert.encoder.layer.8.intermediate.dense.weight\", \"bert.encoder.layer.8.intermediate.dense.bias\", \"bert.encoder.layer.8.output.dense.weight\", \"bert.encoder.layer.8.output.dense.bias\", \"bert.encoder.layer.9.attention.self.query.weight\", \"bert.encoder.layer.9.attention.self.query.bias\", \"bert.encoder.layer.9.attention.self.key.weight\", \"bert.encoder.layer.9.attention.self.key.bias\", \"bert.encoder.layer.9.attention.self.value.weight\", \"bert.encoder.layer.9.attention.self.value.bias\", \"bert.encoder.layer.9.attention.output.dense.weight\", \"bert.encoder.layer.9.attention.output.dense.bias\", \"bert.encoder.layer.9.intermediate.dense.weight\", \"bert.encoder.layer.9.intermediate.dense.bias\", \"bert.encoder.layer.9.output.dense.weight\", \"bert.encoder.layer.9.output.dense.bias\", \"bert.encoder.layer.10.attention.self.query.weight\", \"bert.encoder.layer.10.attention.self.query.bias\", \"bert.encoder.layer.10.attention.self.key.weight\", \"bert.encoder.layer.10.attention.self.key.bias\", \"bert.encoder.layer.10.attention.self.value.weight\", \"bert.encoder.layer.10.attention.self.value.bias\", \"bert.encoder.layer.10.attention.output.dense.weight\", \"bert.encoder.layer.10.attention.output.dense.bias\", \"bert.encoder.layer.10.intermediate.dense.weight\", \"bert.encoder.layer.10.intermediate.dense.bias\", \"bert.encoder.layer.10.output.dense.weight\", \"bert.encoder.layer.10.output.dense.bias\", \"bert.encoder.layer.11.attention.self.query.weight\", \"bert.encoder.layer.11.attention.self.query.bias\", \"bert.encoder.layer.11.attention.self.key.weight\", \"bert.encoder.layer.11.attention.self.key.bias\", \"bert.encoder.layer.11.attention.self.value.weight\", \"bert.encoder.layer.11.attention.self.value.bias\", \"bert.encoder.layer.11.attention.output.dense.weight\", \"bert.encoder.layer.11.attention.output.dense.bias\", \"bert.encoder.layer.11.intermediate.dense.weight\", \"bert.encoder.layer.11.intermediate.dense.bias\", \"bert.encoder.layer.11.output.dense.weight\", \"bert.encoder.layer.11.output.dense.bias\", \"bert.pooler.dense.weight\", \"bert.pooler.dense.bias\", \"decoder.transform.dense.weight\", \"decoder.transform.dense.bias\", \"decoder.decoder.weight\", \"decoder.decoder.bias\". \n\tUnexpected key(s) in state_dict: \"bert.encoder.layer.0.attention.self.query.scale\", \"bert.encoder.layer.0.attention.self.query.zero_point\", \"bert.encoder.layer.0.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.0.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.0.attention.self.key.scale\", \"bert.encoder.layer.0.attention.self.key.zero_point\", \"bert.encoder.layer.0.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.0.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.0.attention.self.value.scale\", \"bert.encoder.layer.0.attention.self.value.zero_point\", \"bert.encoder.layer.0.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.0.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.0.attention.output.dense.scale\", \"bert.encoder.layer.0.attention.output.dense.zero_point\", \"bert.encoder.layer.0.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.0.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.0.intermediate.dense.scale\", \"bert.encoder.layer.0.intermediate.dense.zero_point\", \"bert.encoder.layer.0.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.0.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.0.output.dense.scale\", \"bert.encoder.layer.0.output.dense.zero_point\", \"bert.encoder.layer.0.output.dense._packed_params.dtype\", \"bert.encoder.layer.0.output.dense._packed_params._packed_params\", \"bert.encoder.layer.1.attention.self.query.scale\", \"bert.encoder.layer.1.attention.self.query.zero_point\", \"bert.encoder.layer.1.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.1.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.1.attention.self.key.scale\", \"bert.encoder.layer.1.attention.self.key.zero_point\", \"bert.encoder.layer.1.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.1.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.1.attention.self.value.scale\", \"bert.encoder.layer.1.attention.self.value.zero_point\", \"bert.encoder.layer.1.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.1.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.1.attention.output.dense.scale\", \"bert.encoder.layer.1.attention.output.dense.zero_point\", \"bert.encoder.layer.1.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.1.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.1.intermediate.dense.scale\", \"bert.encoder.layer.1.intermediate.dense.zero_point\", \"bert.encoder.layer.1.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.1.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.1.output.dense.scale\", \"bert.encoder.layer.1.output.dense.zero_point\", \"bert.encoder.layer.1.output.dense._packed_params.dtype\", \"bert.encoder.layer.1.output.dense._packed_params._packed_params\", \"bert.encoder.layer.2.attention.self.query.scale\", \"bert.encoder.layer.2.attention.self.query.zero_point\", \"bert.encoder.layer.2.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.2.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.2.attention.self.key.scale\", \"bert.encoder.layer.2.attention.self.key.zero_point\", \"bert.encoder.layer.2.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.2.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.2.attention.self.value.scale\", \"bert.encoder.layer.2.attention.self.value.zero_point\", \"bert.encoder.layer.2.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.2.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.2.attention.output.dense.scale\", \"bert.encoder.layer.2.attention.output.dense.zero_point\", \"bert.encoder.layer.2.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.2.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.2.intermediate.dense.scale\", \"bert.encoder.layer.2.intermediate.dense.zero_point\", \"bert.encoder.layer.2.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.2.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.2.output.dense.scale\", \"bert.encoder.layer.2.output.dense.zero_point\", \"bert.encoder.layer.2.output.dense._packed_params.dtype\", \"bert.encoder.layer.2.output.dense._packed_params._packed_params\", \"bert.encoder.layer.3.attention.self.query.scale\", \"bert.encoder.layer.3.attention.self.query.zero_point\", \"bert.encoder.layer.3.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.3.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.3.attention.self.key.scale\", \"bert.encoder.layer.3.attention.self.key.zero_point\", \"bert.encoder.layer.3.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.3.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.3.attention.self.value.scale\", \"bert.encoder.layer.3.attention.self.value.zero_point\", \"bert.encoder.layer.3.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.3.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.3.attention.output.dense.scale\", \"bert.encoder.layer.3.attention.output.dense.zero_point\", \"bert.encoder.layer.3.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.3.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.3.intermediate.dense.scale\", \"bert.encoder.layer.3.intermediate.dense.zero_point\", \"bert.encoder.layer.3.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.3.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.3.output.dense.scale\", \"bert.encoder.layer.3.output.dense.zero_point\", \"bert.encoder.layer.3.output.dense._packed_params.dtype\", \"bert.encoder.layer.3.output.dense._packed_params._packed_params\", \"bert.encoder.layer.4.attention.self.query.scale\", \"bert.encoder.layer.4.attention.self.query.zero_point\", \"bert.encoder.layer.4.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.4.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.4.attention.self.key.scale\", \"bert.encoder.layer.4.attention.self.key.zero_point\", \"bert.encoder.layer.4.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.4.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.4.attention.self.value.scale\", \"bert.encoder.layer.4.attention.self.value.zero_point\", \"bert.encoder.layer.4.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.4.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.4.attention.output.dense.scale\", \"bert.encoder.layer.4.attention.output.dense.zero_point\", \"bert.encoder.layer.4.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.4.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.4.intermediate.dense.scale\", \"bert.encoder.layer.4.intermediate.dense.zero_point\", \"bert.encoder.layer.4.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.4.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.4.output.dense.scale\", \"bert.encoder.layer.4.output.dense.zero_point\", \"bert.encoder.layer.4.output.dense._packed_params.dtype\", \"bert.encoder.layer.4.output.dense._packed_params._packed_params\", \"bert.encoder.layer.5.attention.self.query.scale\", \"bert.encoder.layer.5.attention.self.query.zero_point\", \"bert.encoder.layer.5.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.5.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.5.attention.self.key.scale\", \"bert.encoder.layer.5.attention.self.key.zero_point\", \"bert.encoder.layer.5.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.5.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.5.attention.self.value.scale\", \"bert.encoder.layer.5.attention.self.value.zero_point\", \"bert.encoder.layer.5.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.5.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.5.attention.output.dense.scale\", \"bert.encoder.layer.5.attention.output.dense.zero_point\", \"bert.encoder.layer.5.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.5.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.5.intermediate.dense.scale\", \"bert.encoder.layer.5.intermediate.dense.zero_point\", \"bert.encoder.layer.5.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.5.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.5.output.dense.scale\", \"bert.encoder.layer.5.output.dense.zero_point\", \"bert.encoder.layer.5.output.dense._packed_params.dtype\", \"bert.encoder.layer.5.output.dense._packed_params._packed_params\", \"bert.encoder.layer.6.attention.self.query.scale\", \"bert.encoder.layer.6.attention.self.query.zero_point\", \"bert.encoder.layer.6.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.6.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.6.attention.self.key.scale\", \"bert.encoder.layer.6.attention.self.key.zero_point\", \"bert.encoder.layer.6.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.6.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.6.attention.self.value.scale\", \"bert.encoder.layer.6.attention.self.value.zero_point\", \"bert.encoder.layer.6.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.6.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.6.attention.output.dense.scale\", \"bert.encoder.layer.6.attention.output.dense.zero_point\", \"bert.encoder.layer.6.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.6.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.6.intermediate.dense.scale\", \"bert.encoder.layer.6.intermediate.dense.zero_point\", \"bert.encoder.layer.6.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.6.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.6.output.dense.scale\", \"bert.encoder.layer.6.output.dense.zero_point\", \"bert.encoder.layer.6.output.dense._packed_params.dtype\", \"bert.encoder.layer.6.output.dense._packed_params._packed_params\", \"bert.encoder.layer.7.attention.self.query.scale\", \"bert.encoder.layer.7.attention.self.query.zero_point\", \"bert.encoder.layer.7.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.7.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.7.attention.self.key.scale\", \"bert.encoder.layer.7.attention.self.key.zero_point\", \"bert.encoder.layer.7.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.7.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.7.attention.self.value.scale\", \"bert.encoder.layer.7.attention.self.value.zero_point\", \"bert.encoder.layer.7.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.7.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.7.attention.output.dense.scale\", \"bert.encoder.layer.7.attention.output.dense.zero_point\", \"bert.encoder.layer.7.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.7.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.7.intermediate.dense.scale\", \"bert.encoder.layer.7.intermediate.dense.zero_point\", \"bert.encoder.layer.7.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.7.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.7.output.dense.scale\", \"bert.encoder.layer.7.output.dense.zero_point\", \"bert.encoder.layer.7.output.dense._packed_params.dtype\", \"bert.encoder.layer.7.output.dense._packed_params._packed_params\", \"bert.encoder.layer.8.attention.self.query.scale\", \"bert.encoder.layer.8.attention.self.query.zero_point\", \"bert.encoder.layer.8.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.8.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.8.attention.self.key.scale\", \"bert.encoder.layer.8.attention.self.key.zero_point\", \"bert.encoder.layer.8.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.8.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.8.attention.self.value.scale\", \"bert.encoder.layer.8.attention.self.value.zero_point\", \"bert.encoder.layer.8.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.8.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.8.attention.output.dense.scale\", \"bert.encoder.layer.8.attention.output.dense.zero_point\", \"bert.encoder.layer.8.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.8.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.8.intermediate.dense.scale\", \"bert.encoder.layer.8.intermediate.dense.zero_point\", \"bert.encoder.layer.8.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.8.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.8.output.dense.scale\", \"bert.encoder.layer.8.output.dense.zero_point\", \"bert.encoder.layer.8.output.dense._packed_params.dtype\", \"bert.encoder.layer.8.output.dense._packed_params._packed_params\", \"bert.encoder.layer.9.attention.self.query.scale\", \"bert.encoder.layer.9.attention.self.query.zero_point\", \"bert.encoder.layer.9.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.9.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.9.attention.self.key.scale\", \"bert.encoder.layer.9.attention.self.key.zero_point\", \"bert.encoder.layer.9.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.9.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.9.attention.self.value.scale\", \"bert.encoder.layer.9.attention.self.value.zero_point\", \"bert.encoder.layer.9.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.9.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.9.attention.output.dense.scale\", \"bert.encoder.layer.9.attention.output.dense.zero_point\", \"bert.encoder.layer.9.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.9.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.9.intermediate.dense.scale\", \"bert.encoder.layer.9.intermediate.dense.zero_point\", \"bert.encoder.layer.9.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.9.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.9.output.dense.scale\", \"bert.encoder.layer.9.output.dense.zero_point\", \"bert.encoder.layer.9.output.dense._packed_params.dtype\", \"bert.encoder.layer.9.output.dense._packed_params._packed_params\", \"bert.encoder.layer.10.attention.self.query.scale\", \"bert.encoder.layer.10.attention.self.query.zero_point\", \"bert.encoder.layer.10.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.10.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.10.attention.self.key.scale\", \"bert.encoder.layer.10.attention.self.key.zero_point\", \"bert.encoder.layer.10.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.10.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.10.attention.self.value.scale\", \"bert.encoder.layer.10.attention.self.value.zero_point\", \"bert.encoder.layer.10.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.10.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.10.attention.output.dense.scale\", \"bert.encoder.layer.10.attention.output.dense.zero_point\", \"bert.encoder.layer.10.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.10.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.10.intermediate.dense.scale\", \"bert.encoder.layer.10.intermediate.dense.zero_point\", \"bert.encoder.layer.10.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.10.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.10.output.dense.scale\", \"bert.encoder.layer.10.output.dense.zero_point\", \"bert.encoder.layer.10.output.dense._packed_params.dtype\", \"bert.encoder.layer.10.output.dense._packed_params._packed_params\", \"bert.encoder.layer.11.attention.self.query.scale\", \"bert.encoder.layer.11.attention.self.query.zero_point\", \"bert.encoder.layer.11.attention.self.query._packed_params.dtype\", \"bert.encoder.layer.11.attention.self.query._packed_params._packed_params\", \"bert.encoder.layer.11.attention.self.key.scale\", \"bert.encoder.layer.11.attention.self.key.zero_point\", \"bert.encoder.layer.11.attention.self.key._packed_params.dtype\", \"bert.encoder.layer.11.attention.self.key._packed_params._packed_params\", \"bert.encoder.layer.11.attention.self.value.scale\", \"bert.encoder.layer.11.attention.self.value.zero_point\", \"bert.encoder.layer.11.attention.self.value._packed_params.dtype\", \"bert.encoder.layer.11.attention.self.value._packed_params._packed_params\", \"bert.encoder.layer.11.attention.output.dense.scale\", \"bert.encoder.layer.11.attention.output.dense.zero_point\", \"bert.encoder.layer.11.attention.output.dense._packed_params.dtype\", \"bert.encoder.layer.11.attention.output.dense._packed_params._packed_params\", \"bert.encoder.layer.11.intermediate.dense.scale\", \"bert.encoder.layer.11.intermediate.dense.zero_point\", \"bert.encoder.layer.11.intermediate.dense._packed_params.dtype\", \"bert.encoder.layer.11.intermediate.dense._packed_params._packed_params\", \"bert.encoder.layer.11.output.dense.scale\", \"bert.encoder.layer.11.output.dense.zero_point\", \"bert.encoder.layer.11.output.dense._packed_params.dtype\", \"bert.encoder.layer.11.output.dense._packed_params._packed_params\", \"bert.pooler.dense.scale\", \"bert.pooler.dense.zero_point\", \"bert.pooler.dense._packed_params.dtype\", \"bert.pooler.dense._packed_params._packed_params\", \"decoder.transform.dense.scale\", \"decoder.transform.dense.zero_point\", \"decoder.transform.dense._packed_params.dtype\", \"decoder.transform.dense._packed_params._packed_params\", \"decoder.decoder.scale\", \"decoder.decoder.zero_point\", \"decoder.decoder._packed_params.dtype\", \"decoder.decoder._packed_params._packed_params\". "
     ]
    }
   ],
   "source": [
    "# 加载字典\n",
    "word2idx,_ = load_chinese_base_vocab(vocab_path=vocab_text,simplfied=True)\n",
    "tokenizer = Tokenizer(word2idx)\n",
    "# 定义模型\n",
    "bert_model = load_bert(word2idx,model_name=model_name)\n",
    "bert_model.set_device(device)\n",
    "bert_model.eval()\n",
    "bert_model.load_all_params(model_path=model, device=device)\n",
    "bert_model2 = load_bert(word2idx, model_name=model_name)\n",
    "bert_model2.set_device(device_int8)\n",
    "bert_model2.eval()\n",
    "bert_model2.load_all_params(model_path=model_int8, device=device_int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "./model_file/trained_model/summary_roberta_wwm_256.bin loaded!\n"
     ]
    }
   ],
   "source": [
    "bert_model2 = load_bert(word2idx, model_name=model_name)\n",
    "bert_model2.set_device(device)\n",
    "bert_model2.eval()\n",
    "bert_model2.load_all_params(model_path=model2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(bert_model, \"summary.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             article  \\\n",
       "0  四海网讯，近日，有媒体报道称：章子怡真怀孕了!报道还援引知情人士消息称，“章子怡怀孕大概四五...   \n",
       "1  中新社西宁11月22日电(赵凛松)青海省林业厅野生动植物和自然保护区管理局高级工程师张毓22...   \n",
       "2  内容提要：因为早早结婚，今年20岁的杨丽（化名）已经是一个三岁小孩的妈妈。今年10月31日，...   \n",
       "3  发布日期：2015-07-1215:20:00滁州市气象台2015年07月12日15时20分...   \n",
       "4  本报讯(记者陈雪实习生王健)日前，在我省公安机关公布的数据显示，在用药水泡制豆芽的犯罪行为的...   \n",
       "\n",
       "                                             summary  \n",
       "0          知情人透露章子怡怀孕后，父母很高兴。章母已开始悉心照料。据悉，预产期大概是12月底  \n",
       "1                            青海首次野外发现濒危大火烈鸟 尚不清楚具体来源  \n",
       "2                           东莞少女妈妈不愿带孩子 自杀被救后携女出走（图）  \n",
       "3  滁州市发布雷电黄色预警：目前我市西部有较强对流云团向东南方向移动，预计6小时内我市部分地区将...  \n",
       "4                          延安豆芽现已疯涨至每斤四元 查处严格后商贩不卖豆芽  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article</th>\n      <th>summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>四海网讯，近日，有媒体报道称：章子怡真怀孕了!报道还援引知情人士消息称，“章子怡怀孕大概四五...</td>\n      <td>知情人透露章子怡怀孕后，父母很高兴。章母已开始悉心照料。据悉，预产期大概是12月底</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>中新社西宁11月22日电(赵凛松)青海省林业厅野生动植物和自然保护区管理局高级工程师张毓22...</td>\n      <td>青海首次野外发现濒危大火烈鸟 尚不清楚具体来源</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>内容提要：因为早早结婚，今年20岁的杨丽（化名）已经是一个三岁小孩的妈妈。今年10月31日，...</td>\n      <td>东莞少女妈妈不愿带孩子 自杀被救后携女出走（图）</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>发布日期：2015-07-1215:20:00滁州市气象台2015年07月12日15时20分...</td>\n      <td>滁州市发布雷电黄色预警：目前我市西部有较强对流云团向东南方向移动，预计6小时内我市部分地区将...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>本报讯(记者陈雪实习生王健)日前，在我省公安机关公布的数据显示，在用药水泡制豆芽的犯罪行为的...</td>\n      <td>延安豆芽现已疯涨至每斤四元 查处严格后商贩不卖豆芽</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./dataset/train_with_summ.csv\")\n",
    "del df[\"Unnamed: 0\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "x = df[\"article\"][0]\n",
    "y = df[\"summary\"][0]\n",
    "token_ids, token_type_ids = tokenizer.encode(x,y,128)\n",
    "target_ids=torch.tensor(token_ids[1:])\n",
    "# token_ids = (1, token_ids)\n",
    "token_ids = torch.tensor(token_ids)\n",
    "token_type_ids = torch.tensor(token_type_ids)\n",
    "x = (token_ids, token_type_ids, target_ids,)\n",
    "torch.onnx.export(bert_model,               # model being run\n",
    "                  x,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"bert_summary.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})\n",
    "# vis = make_dot(bert_model(token_ids,token_type_ids,labels=target_ids),params=dict(bert_model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2idx,_ = load_chinese_base_vocab(vocab_path=vocab_text,simplfied=True)\n",
    "bert_model2 = load_bert(word2idx, model_name=model_name)\n",
    "bert_model2.set_device(device)\n",
    "bert_model2.eval()\n",
    "bert_model2.load_all_params(model_path=model2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = df[\"article\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    四海网讯，近日，有媒体报道称：章子怡真怀孕了!报道还援引知情人士消息称，“章子怡怀孕大概四五...\n",
       "1    中新社西宁11月22日电(赵凛松)青海省林业厅野生动植物和自然保护区管理局高级工程师张毓22...\n",
       "2    内容提要：因为早早结婚，今年20岁的杨丽（化名）已经是一个三岁小孩的妈妈。今年10月31日，...\n",
       "Name: article, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "res: 媒 体 称 章 子 怡 怀 孕 四 五 个 月 ，预 产 期 是 年 底 前 后 ，现 在 已 经 不 接 工 作 了 。\n",
      "res256: 曝 章 子 怡 怀 孕 四 五 个 月 ，预 产 期 是 年 底 前 后 ，已 经 不 接 工 作 。\n",
      "res: 青 海 省 林 业 厅 野 生 动 植 物 和 自 然 保 护 区 管 理 局 高 级 工 程 师 称 ，出 现 在 海 西 州 境 内 的 三 只 三 只 三 只 。\n",
      "res256: 青 海 省 林 业 厅 野 生 动 植 物 和 自 然 保 护 区 管 理 局 高 级 工 程 师 称 ，出 现 在 海 西 州 境 内 的 三 只 三 只 ，出 现 在 海 西 州 境 内 的 三 只 。\n",
      "res: 东 莞 ：20 岁 女 孩 与 老 公 大 吵 一 架 离 家 出 走 ，被 父 亲 拒 绝 后 欲 跳 楼 轻 轻 轻 轻 轻 轻 。\n",
      "res256: 东 莞 ：20 岁 女 孩 因 早 早 结 婚 ，父 亲 拒 绝 ，欲 跳 楼 轻 轻 轻 轻 ，被 父 亲 拒 绝 后 ，欲 跳 楼 轻 轻 。\n"
     ]
    }
   ],
   "source": [
    "for text in test_data:\n",
    "    with torch.no_grad():\n",
    "        res = bert_model.generate(text, beam_size=4,out_max_length=150)\n",
    "        res2 = bert_model2.generate(text, beam_size=4,out_max_length=150)\n",
    "        print('res: {}\\nres256: {}'.format(res, res2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import torch\n",
    "def convert(bin_path, ckpt_path):\n",
    "    with tf.Session() as sess:\n",
    "        for var_name, value in torch.load(bin_path, map_location='cpu').items():\n",
    "            print(var_name)\n",
    "            tf.Variable(initial_value=value, name=var_name)\n",
    "            saver = tf.train.Saver()\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            saver.save(sess, ckpt_path)\n",
    "bin_path = 'F:\\\\我的坚果云\\\\毕业论文\\\\code\\\\bert_seq2seq-master\\\\bert_seq2seq-master\\\\model_file\\\\trained_model\\\\summary_roberta_wwm_256.bin'\n",
    "ckpt_path = 'model_file/bert_model.ckpt'\n",
    "convert(bin_path, ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}